{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL63-3N8jlym"
      },
      "source": [
        "##Implementation of simple RNN and LSTM for text classification (sentiment analysis)\n",
        "- In this python file, we will add multiple layers, to reduce the overfit\n",
        "  - We will use dropouts\n",
        "  - Batch normalization\n",
        "  - Layer Normalization\n",
        "  - Stacking\n",
        "  - Bidirectional LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RthMTNhNjKS1",
        "outputId": "de257e3c-d102-4ebb-f62b-c4302dbdf47f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, BatchNormalization, Dropout, Embedding, LayerNormalization, Bidirectional\n",
        "from tensorflow.keras.layers import LayerNormalization\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "## text preprocessing modules\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from gensim.models import Word2Vec\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8ZZ2XXOjlgiL"
      },
      "outputs": [],
      "source": [
        "### Load the data\n",
        "review_data=pd.read_csv(\"/content/Imdb_preprocessed (1).csv.gz\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac3ew_SLB1Za",
        "outputId": "0d151924-8b9c-44d8-8ad2-84d72b131d41"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'review', 'sentiment', 'cleaned_reveiws_w/o_SW',\n",
              "       'cleaned_reviews_with_SW', 'cleaned_reviews_with_SW2', 'review_length',\n",
              "       'sentiment_target'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DO7pJSClvni",
        "outputId": "6f92b8dd-beb9-4ecd-a8df-f5a3dabded56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['reviewer mentioned watching episode hooked right exactly happened thing struck brutality unflinching scene violence set right word trust faint hearted timid pull punch regard drug sex violence hardcore classic use word called nickname given oswald maximum security state penitentary focus mainly emerald city experimental section prison cell glass front face inwards privacy high agenda city home aryan muslim gangsta latino christian italian irish scuffle death stare dodgy dealing shady agreement far away say main appeal fact go show dare forget pretty picture painted mainstream audience forget charm forget romance mess episode saw struck nasty surreal say ready watched developed taste got accustomed high level graphic violence violence injustice crooked guard sold nickel inmate kill order away mannered middle class inmate turned prison bitch lack street skill prison experience watching comfortable uncomfortable viewing touch darker ',\n",
              " 'wonderful little production filming technique unassuming oldtimebbc fashion give comforting discomforting sense realism entire piece actor extremely chosen michael sheen got polari voice pat truly seamless editing guided reference williams diary entry worth watching terrificly written performed piece masterful production great master comedy life realism really come home little thing fantasy guard use traditional dream technique remains solid disappears play knowledge sens particularly scene concerning orton halliwell set particularly flat halliwells mural decorating surface terribly ']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "### Take the reviews text as a list of elements and then perform the basic preprocessing \n",
        "text= list(review_data['cleaned_reviews_with_SW'])\n",
        "text[0:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wszD7ZxfmIDM"
      },
      "outputs": [],
      "source": [
        "### Now the reviews are faily clean, we will tokenize the reviews and get word embeddings for these\n",
        "tokenizer=Tokenizer(num_words=5000,lower=True,oov_token='UNK')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REkHMwJxmLLa",
        "outputId": "b4e86372-24f4-4ec2-b23b-8437d9f89f4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000 49500 500\n"
          ]
        }
      ],
      "source": [
        "## Before applying the tokenizer, lets split the data into train test\n",
        "train_text=text[:len(text)-500]\n",
        "test_text=text[-500:]\n",
        "print(len(text),len(train_text),len(test_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9_R2aydlmOHE"
      },
      "outputs": [],
      "source": [
        "### Now lets tokenize the reviews\n",
        "tokenizer.fit_on_texts(train_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSEz5uXMmn6S",
        "outputId": "9a76f096-4839-4190-c079-e4d6ce4a4fef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49500 500\n"
          ]
        }
      ],
      "source": [
        "review_data['sentiment'].replace(['positive','negative'],[1,0],inplace=True)\n",
        "review_data['sentiment'].value_counts()\n",
        "\n",
        "Y=list(review_data['sentiment'])\n",
        "train_y=Y[:len(Y)-500]\n",
        "test_y=Y[-500:]\n",
        "print(len(train_y),len(test_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZiuQYl_mrcp",
        "outputId": "f7386430-1a0a-4922-adf6-4a070253239e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-3982d415d8a7>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  train_indices=np.asarray(train_indices)\n"
          ]
        }
      ],
      "source": [
        "train_indices=tokenizer.texts_to_sequences(train_text)\n",
        "train_indices=np.asarray(train_indices)\n",
        "train_y=np.asarray(train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WiODCyNwmXje"
      },
      "outputs": [],
      "source": [
        "## As mentioned we are limiting the number of words say 64\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "max_length=64\n",
        "train_indices=pad_sequences(train_indices,maxlen=max_length,padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WEkc5nDZoSft"
      },
      "outputs": [],
      "source": [
        "test_indices=tokenizer.texts_to_sequences(test_text)\n",
        "test_indices=pad_sequences(test_indices,maxlen=max_length,padding='post')\n",
        "test_indices=np.asarray(test_indices)\n",
        "test_y=np.asarray(test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlAPnKurmjRs",
        "outputId": "166d016a-53cc-4ea3-9a33-409fed78589d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 64, 100)           13522400  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64, 100)           0         \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 32)                4256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,526,689\n",
            "Trainable params: 13,526,689\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "### Creating the model architecture Using dropouts\n",
        "vocab= len(tokenizer.word_index)+1\n",
        "model= Sequential()\n",
        "model.add(Embedding(input_dim=vocab,output_dim=100,input_length=max_length))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeB0nkc3n8Q3",
        "outputId": "b4e95e11-9759-4b4b-b2c8-a79f4e5c6c97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1547/1547 [==============================] - 573s 370ms/step - loss: 0.2947 - accuracy: 0.8794\n",
            "Accuracy: 85.00%\n"
          ]
        }
      ],
      "source": [
        "model.fit(train_indices,train_y,batch_size=32,epochs=1)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(test_indices, test_y, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sc9jXMyhofPX",
        "outputId": "7486b357-c25a-44d5-8f6f-6d62d98bc403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 64, 100)           13522400  \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64, 100)           0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 32)                17024     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,539,457\n",
            "Trainable params: 13,539,457\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "## Creating the model architecture-- Dropouts with LSTM\n",
        "vocab= len(tokenizer.word_index)+1\n",
        "model= Sequential()\n",
        "model.add(Embedding(input_dim=vocab,output_dim=100,input_length=max_length))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vpRwyTMyJNV",
        "outputId": "061f969c-89c4-4bcb-8d0d-cea0c393fe39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1547/1547 [==============================] - 506s 325ms/step - loss: 0.3799 - accuracy: 0.8278\n",
            "Accuracy: 84.80%\n"
          ]
        }
      ],
      "source": [
        "model.fit(train_indices,train_y,batch_size=32)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(test_indices, test_y, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLpKH11ryM3d",
        "outputId": "9d31b9d0-3301-4cfb-c8bf-fbea525a8a06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 64, 100)           13522400  \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64, 100)           0         \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 32)                4256      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32)               128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,526,817\n",
            "Trainable params: 13,526,753\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "#### Lets Look at having a batch normalization alng with dropout \n",
        "vocab= len(tokenizer.word_index)+1\n",
        "model= Sequential()\n",
        "model.add(Embedding(input_dim=vocab,output_dim=100,input_length=max_length))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoS0KcAaMxRd",
        "outputId": "e9a1f429-3968-4987-e9c9-2320f373aff3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1547/1547 [==============================] - 465s 300ms/step - loss: 0.5819 - accuracy: 0.6737\n",
            "Accuracy: 82.60%\n"
          ]
        }
      ],
      "source": [
        "model.fit(train_indices,train_y,batch_size=32)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(test_indices, test_y, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKwezBvoROTg",
        "outputId": "a8c4e3b9-4b7b-4d37-ed6d-a2b1bcd937f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 64, 100)           13522400  \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 64, 100)           0         \n",
            "                                                                 \n",
            " simple_rnn_2 (SimpleRNN)    (None, 32)                4256      \n",
            "                                                                 \n",
            " layer_normalization (LayerN  (None, 32)               64        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,526,753\n",
            "Trainable params: 13,526,753\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "#### Lets Look at having a layer normalization alng with dropout \n",
        "vocab= len(tokenizer.word_index)+1\n",
        "model= Sequential()\n",
        "model.add(Embedding(input_dim=vocab,output_dim=100,input_length=max_length))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(LayerNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEUBTstPRaco",
        "outputId": "9b8ad4d4-09d1-4d07-815f-142e3e4a6560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1547/1547 [==============================] - 464s 299ms/step - loss: 0.5566 - accuracy: 0.7113\n",
            "Accuracy: 81.40%\n"
          ]
        }
      ],
      "source": [
        "model.fit(train_indices,train_y,batch_size=32)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(test_indices, test_y, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIF3q2QJN9PS",
        "outputId": "1cc62490-7da5-45b8-a5d8-e2eba295d101"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 64, 100)           13522400  \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 64, 100)           0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 64)               8512      \n",
            " l)                                                              \n",
            "                                                                 \n",
            " layer_normalization_1 (Laye  (None, 64)               128       \n",
            " rNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,531,105\n",
            "Trainable params: 13,531,105\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "### Strengthening using bidirectional LSTM\n",
        "vocab= len(tokenizer.word_index)+1\n",
        "model= Sequential()\n",
        "model.add(Embedding(input_dim=vocab,output_dim=100,input_length=max_length))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Bidirectional(SimpleRNN(32)))\n",
        "model.add(LayerNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RQfibThR4dB",
        "outputId": "434e51a5-0c12-47d8-87ae-8fe694fd5739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1547/1547 [==============================] - 526s 338ms/step - loss: 0.4799 - accuracy: 0.7673\n",
            "Accuracy: 82.40%\n"
          ]
        }
      ],
      "source": [
        "model.fit(train_indices,train_y,batch_size=32)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(test_indices, test_y, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5m7GNYeqUpa0",
        "outputId": "a89da620-42db-4822-dee8-9ff7449807b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 64, 100)           13522400  \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 64, 100)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64, 32)            17024     \n",
            "                                                                 \n",
            " layer_normalization_2 (Laye  (None, 64, 32)           64        \n",
            " rNormalization)                                                 \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 32)                8320      \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,547,841\n",
            "Trainable params: 13,547,841\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "### Stacked LSTM\n",
        "vocab= len(tokenizer.word_index)+1\n",
        "model= Sequential()\n",
        "model.add(Embedding(input_dim=vocab,output_dim=100,input_length=max_length))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(32,return_sequences=True))\n",
        "model.add(LayerNormalization())\n",
        "model.add(LSTM(32))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "0siPLtWTYRDq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "881a1efc-defe-4e2c-924b-6650bd59b511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1547/1547 [==============================] - 580s 372ms/step - loss: 0.3994 - accuracy: 0.8185\n",
            "Accuracy: 83.40%\n"
          ]
        }
      ],
      "source": [
        "model.fit(train_indices,train_y,batch_size=32)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(test_indices, test_y, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ExRMN9S7udpu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}